{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f3c68f",
   "metadata": {},
   "source": [
    "# Practice Lab: Decision Trees\n",
    "\n",
    "Bu alıştırmada, sıfırdan bir karar ağacı (decision tree) uygulayacak ve bunu bir mantarın yenilebilir mi yoksa zehirli mi olduğunu sınıflandırma görevinde kullanacaksınız.\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 -  Problem Statement](#2)\n",
    "- [ 3 - Dataset](#3)\n",
    "  - [ 3.1 One hot encoded dataset](#3.1)\n",
    "- [ 4 - Decision Tree Refresher](#4)\n",
    "  - [ 4.1  Calculate entropy](#4.1)\n",
    "    - [ Exercise 1](#ex01)\n",
    "  - [ 4.2  Split dataset](#4.2)\n",
    "    - [ Exercise 2](#ex02)\n",
    "  - [ 4.3  Calculate information gain](#4.3)\n",
    "    - [ Exercise 3](#ex03)\n",
    "  - [ 4.4  Get best split](#4.4)\n",
    "    - [ Exercise 4](#ex04)\n",
    "- [ 5 - Building the tree](#5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb909b94",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "\n",
    "## 1 - Paketler\n",
    "\n",
    "Öncelikle, bu ödev sırasında ihtiyacınız olacak tüm paketleri içe aktarmak için aşağıdaki hücreyi çalıştıralım.\n",
    "\n",
    "* [numpy](https://www.numpy.org): Python’da matrislerle çalışmak için temel paket.\n",
    "* [matplotlib](https://matplotlib.org): Python’da grafik çizmek için yaygın bir kütüphane.\n",
    "* `utils.py`: Bu ödev için yardımcı fonksiyonları içerir. Bu dosyadaki kodu değiştirmeniz gerekmez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b026a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1065960",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "\n",
    "## 2 - Problem Tanımı\n",
    "\n",
    "Varsayalım ki, **yabani mantar yetiştirip satan bir şirket kuruyorsunuz**.\n",
    "\n",
    "* Tüm mantarlar yenilebilir olmadığından, verilen bir mantarın fiziksel özelliklerine bakarak **yenilebilir mi yoksa zehirli mi olduğunu** söyleyebilmek istiyorsunuz.\n",
    "* Bu görev için kullanabileceğiniz mevcut bazı verileriniz var.\n",
    "\n",
    "Bu verileri kullanarak hangi mantarların güvenle satılabileceğini belirleyebilir misiniz?\n",
    "\n",
    "**Not:** Kullanılan veri seti sadece örnekleme amaçlıdır. Yenilebilir mantarları tanımlamak için bir kılavuz değildir.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"3\"></a>\n",
    "\n",
    "## 3 - Veri Seti\n",
    "\n",
    "Bu görev için veri setini yükleyerek başlayacaksınız. Topladığınız veri seti aşağıdaki gibidir:\n",
    "\n",
    "| Cap Color | Stalk Shape | Solitary | Edible |\n",
    "| :-------: | :---------: | :------: | :----: |\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |   Tapering  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    Yes   |    0   |\n",
    "|    Red    |  Enlarging  |    No    |    0   |\n",
    "|   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "|    Red    |   Tapering  |    No    |    1   |\n",
    "|   Brown   |  Enlarging  |    No    |    0   |\n",
    "\n",
    "* 10 mantar örneğiniz var. Her bir örnek için:\n",
    "\n",
    "  * Üç özellik:\n",
    "\n",
    "    * Cap Color (`Brown` veya `Red`)\n",
    "    * Stalk Shape (`Tapering` veya `Enlarging`)\n",
    "    * Solitary (`Yes` veya `No`)\n",
    "  * Etiket:\n",
    "\n",
    "    * Edible (`1` = yenilebilir, `0` = zehirli)\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "\n",
    "### 3.1 One-hot encoded veri seti\n",
    "\n",
    "Kolaylık olması için, özellikleri **one-hot encoding** ile dönüştürdük (0 veya 1 değerli özellikler):\n",
    "\n",
    "| Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
    "| :-------: | :------------------: | :------: | :----: |\n",
    "|     1     |           1          |     1    |    1   |\n",
    "|     1     |           0          |     1    |    1   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "|     1     |           1          |     1    |    1   |\n",
    "|     0     |           1          |     1    |    0   |\n",
    "|     0     |           0          |     0    |    0   |\n",
    "|     1     |           0          |     1    |    1   |\n",
    "|     0     |           1          |     0    |    1   |\n",
    "|     1     |           0          |     0    |    0   |\n",
    "\n",
    "Buna göre:\n",
    "\n",
    "* `X_train` her örnek için üç özelliği içerir:\n",
    "\n",
    "  * **Brown Cap** (`1` = Brown, `0` = Red)\n",
    "  * **Tapering Stalk Shape** (`1` = Tapering, `0` = Enlarging)\n",
    "  * **Solitary** (`1` = Yes, `0` = No)\n",
    "\n",
    "* `y_train` mantarın yenilebilirliğini gösterir:\n",
    "\n",
    "  * `1` = yenilebilir\n",
    "  * `0` = zehirli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4982e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04110060",
   "metadata": {},
   "source": [
    "#### Değişkenleri İnceleyelim\n",
    "\n",
    "Veri setinize daha yakından bakalım.\n",
    "\n",
    "* Başlamak için iyi bir yol, her bir değişkeni yazdırmak ve içeriğini gözlemlemektir.\n",
    "\n",
    "Aşağıdaki kod, `X_train`’in ilk birkaç öğesini ve değişkenin tipini yazdırır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef017c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of X_train:\n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
    "print(\"Type of X_train:\",type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644b0bc3",
   "metadata": {},
   "source": [
    "Now, let's do the same for `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3789a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of y_train: [1 1 0 0 1]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of y_train:\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9abc8",
   "metadata": {},
   "source": [
    "#### Değişkenlerin Boyutlarını Kontrol Edelim\n",
    "\n",
    "Veri setinizi daha iyi anlamanın bir diğer yolu da boyutlarını incelemektir.\n",
    "\n",
    "`X_train` ve `y_train`’in **shape** değerlerini yazdırarak veri setinizde kaç eğitim örneği olduğunu görebilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d2e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (10, 3)\n",
      "The shape of y_train is:  (10,)\n",
      "Number of training examples (m): 10\n"
     ]
    }
   ],
   "source": [
    "print('X_train’in boyutu:', X_train.shape)\n",
    "print('y_train’in boyutu:', y_train.shape)\n",
    "print('Eğitim örneklerinin sayısı (m):', len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2127ca1",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "\n",
    "## 4 - Karar Ağacı (Decision Tree) Yenileme\n",
    "\n",
    "Bu uygulama laboratuvarında, sağlanan veri setine dayanarak bir **karar ağacı** oluşturacaksınız.\n",
    "\n",
    "* Karar ağacı oluşturma adımlarını hatırlayalım:\n",
    "\n",
    "  * Tüm örneklerle **root node**’dan başlayın\n",
    "  * Tüm olası özellikler için **information gain** hesaplayın ve en yüksek bilgi kazancını veren özelliği seçin\n",
    "  * Seçilen özelliğe göre veri setini bölün ve ağacın sol ve sağ dallarını oluşturun\n",
    "  * Durma kriteri karşılanana kadar bölme işlemini tekrarlayın\n",
    "\n",
    "* Bu laboratuvarda uygulayacağınız fonksiyonlar şunlardır:\n",
    "\n",
    "  * Bir node’daki **entropy**’yi hesaplamak\n",
    "  * Belirli bir özelliğe göre node’u **sol ve sağ dallara** bölmek\n",
    "  * Belirli bir özellik üzerinde bölme yapmanın **information gain** değerini hesaplamak\n",
    "  * **Information gain’i maksimize eden özelliği seçmek**\n",
    "\n",
    "* Daha sonra, uyguladığınız yardımcı fonksiyonları kullanarak, durma kriteri karşılanana kadar bölme işlemini tekrarlayarak bir karar ağacı oluşturacağız.\n",
    "\n",
    "  * Bu lab için seçilen durma kriteri, maksimum derinliğin **2** olarak ayarlanmasıdır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45943d1",
   "metadata": {},
   "source": [
    "<a name=\"4.1\"></a>\n",
    "\n",
    "### 4.1 Entropy Hesaplama\n",
    "\n",
    "Öncelikle, bir node’daki **entropy**’yi (saflık ölçüsü) hesaplayan bir yardımcı fonksiyon olan `compute_entropy`’yi yazacaksınız.\n",
    "\n",
    "* Fonksiyon, node’daki örneklerin **yenilebilir (`1`)** mi yoksa **zehirli (`0`)** mı olduğunu belirten bir numpy dizisi (`y`) alır.\n",
    "\n",
    "Aşağıdaki adımları tamamlayın:\n",
    "\n",
    "* $p_1$’i hesaplayın: Bu, node’daki yenilebilir örneklerin oranıdır (`y` dizisinde değeri `1` olanlar).\n",
    "* Entropy formülü:\n",
    "\n",
    "$$H(p_1) = -p_1 \\log_2(p_1) - (1- p_1) \\log_2(1- p_1)$$\n",
    "\n",
    "**Notlar:**\n",
    "\n",
    "* Logaritma **taban 2** ile hesaplanır\n",
    "* Hesaplama sırasında, $0\\log_2(0) = 0$ olarak alınır. Yani, `p_1 = 0` veya `p_1 = 1` ise entropy `0` olarak ayarlanır\n",
    "* Node’daki veri boşsa (`len(y) == 0`), entropy `0` olarak döndürülmelidir\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"ex01\"></a>\n",
    "\n",
    "### Alıştırma 1\n",
    "\n",
    "Lütfen `compute_entropy()` fonksiyonunu yukarıdaki talimatlara göre tamamlayın.\n",
    "\n",
    "Takılırsanız, hücre altındaki ipuçlarını kullanabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f787bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: compute_entropy\n",
    "\n",
    "def compute_entropy(y):\n",
    "    \"\"\"\n",
    "    Bir node'daki entropy'yi hesaplar.\n",
    "    \n",
    "    Args:\n",
    "       y (ndarray): Node'daki her örneğin yenilebilir (`1`) veya zehirli (`0`) olduğunu belirten Numpy array\n",
    "       \n",
    "    Returns:\n",
    "        entropy (float): Node'daki entropy\n",
    "    \"\"\"\n",
    "    entropy = 0.\n",
    "    \n",
    "    ### KODU BURADAN BAŞLAT ###\n",
    "    if len(y) != 0:\n",
    "        p1 = len(y[y == 1]) / len(y)  # Yenilebilir örneklerin oranı\n",
    "        # p1 = 0 veya 1 ise entropy 0 olacak şekilde ayarlayın\n",
    "        if p1 != 0 and p1 != 1:\n",
    "            entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)\n",
    "        else:\n",
    "            entropy = 0\n",
    "    ### KODU BURADA BİTİR ###\n",
    "    \n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420cdfc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    \n",
    "    \n",
    "   * To calculate `p1`\n",
    "       * You can get the subset of examples in `y` that have the value `1` as `y[y == 1]`\n",
    "       * You can use `len(y)` to get the number of examples in `y`\n",
    "   * To calculate `entropy`\n",
    "       * <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.log2.html\">np.log2</a> let's you calculate the logarithm to base 2 for a numpy array\n",
    "       * If the value of `p1` is 0 or 1, make sure to set the entropy to `0` \n",
    "     \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b> Click for more hints</b></font></summary>\n",
    "        \n",
    "    * Here's how you can structure the overall implementation for this function\n",
    "    ```python \n",
    "    def compute_entropy(y):\n",
    "        \n",
    "        # You need to return the following variables correctly\n",
    "        entropy = 0.\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        if len(y) != 0:\n",
    "            # Your code here to calculate the fraction of edible examples (i.e with value = 1 in y)\n",
    "            p1 =\n",
    "\n",
    "            # For p1 = 0 and 1, set the entropy to 0 (to handle 0log0)\n",
    "            if p1 != 0 and p1 != 1:\n",
    "                # Your code here to calculate the entropy using the formula provided above\n",
    "                entropy = \n",
    "            else:\n",
    "                entropy = 0. \n",
    "        ### END CODE HERE ###        \n",
    "\n",
    "        return entropy\n",
    "    ```\n",
    "    \n",
    "    If you're still stuck, you can check the hints presented below to figure out how to calculate `p1` and `entropy`.\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate p1</b></font></summary>\n",
    "           &emsp; &emsp; You can compute p1 as <code>p1 = len(y[y == 1]) / len(y) </code>\n",
    "    </details>\n",
    "\n",
    "     <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate entropy</b></font></summary>\n",
    "          &emsp; &emsp; You can compute entropy as <code>entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)</code>\n",
    "    </details>\n",
    "        \n",
    "    </details>\n",
    "\n",
    "</details>\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b6e56",
   "metadata": {},
   "source": [
    "Doğru implementasyonu kontrol etmek için aşağıdaki test kodunu çalıştırabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at root node:  1.0\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Root node'daki entropy'yi hesaplayalım (tüm örneklerle)\n",
    "# 5 yenilebilir ve 5 zehirli mantar olduğu için entropy 1 olmalı\n",
    "\n",
    "print(\"Root node'daki entropy: \", compute_entropy(y_train)) \n",
    "\n",
    "# BİRİM TESTLERİ\n",
    "compute_entropy_test(compute_entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061ea62",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Entropy at root node:<b> 1.0 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec1cfe",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "\n",
    "### 4.2 Veri Setini Bölme\n",
    "\n",
    "Sonraki adımda, `split_dataset` adında bir yardımcı fonksiyon yazacaksınız. Bu fonksiyon, bir node’daki veriyi ve bölünecek özelliği alır ve veriyi **sol ve sağ dallara** böler. Daha sonra bu bölmenin ne kadar iyi olduğunu hesaplayacağız.\n",
    "\n",
    "* Fonksiyon, node’daki veri noktalarının indeksleri (`node_indices`) ve bölünecek özelliği alır.\n",
    "* Veriyi böler ve **sol ve sağ dallardaki indeks alt kümelerini** döndürür.\n",
    "* Örneğin, root node’dan başlıyorsak (`node_indices = [0,1,2,3,4,5,6,7,8,9]`) ve feature `0`’ı seçtiysek (örneklerin kahverengi kapaklı olup olmadığı),\n",
    "\n",
    "  * Fonksiyonun çıktısı: `left_indices = [0,1,2,3,4,7,9]` ve `right_indices = [5,6,8]` olacaktır.\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"ex02\"></a>\n",
    "\n",
    "### Alıştırma 2\n",
    "\n",
    "Aşağıdaki `split_dataset()` fonksiyonunu tamamlayın:\n",
    "\n",
    "* Her `node_indices` içindeki indeks için:\n",
    "\n",
    "  * Eğer `X`’te o index ve feature değerinin `1` ise, indeksi `left_indices`’e ekleyin\n",
    "  * Eğer değer `0` ise, indeksi `right_indices`’e ekleyin\n",
    "\n",
    "Takılırsanız, hücre altındaki ipuçlarını kullanabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a373fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: split_dataset\n",
    "\n",
    "def split_dataset(X, node_indices, feature):\n",
    "    \"\"\"\n",
    "    Verilen node'daki veriyi sol ve sağ dallara böler.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): Veri matrisi (n_samples, n_features)\n",
    "        node_indices (list): Bu adımda dikkate alınan örneklerin indeksleri\n",
    "        feature (int): Bölünecek feature'ün indeksi\n",
    "    \n",
    "    Returns:\n",
    "        left_indices (list): Feature değeri 1 olan indeksler\n",
    "        right_indices (list): Feature değeri 0 olan indeksler\n",
    "    \"\"\"\n",
    "    \n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    \n",
    "    ### KODU BURADAN BAŞLAT ###\n",
    "    for i in node_indices:   \n",
    "        if X[i][feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    ### KODU BURADA BİTİR ###\n",
    "        \n",
    "    return left_indices, right_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db81ad2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>İpuçları için tıklayın</b></font></summary>\n",
    "\n",
    "* İşte bu fonksiyonun genel implementasyonunu nasıl yapılandırabileceğiniz:\n",
    "  ```python\n",
    "  def split_dataset(X, node_indices, feature):\n",
    "\n",
    "  # Döndürmeniz gereken değişkenler\n",
    "\n",
    "  left_indices = []\n",
    "  right_indices = []\n",
    "\n",
    "  ### KODU BURADAN BAŞLAT\n",
    "\n",
    "  # O node’daki örneklerin indekslerinden geç\n",
    "\n",
    "  for i in node_indices:\n",
    "  if # Bu indeksteki X değerinin feature için 1 olup olmadığını kontrol edin\n",
    "  left_indices.append(i)\n",
    "  else:\n",
    "  right_indices.append(i)\n",
    "\n",
    "  ### KODU BURADA BİTİR\n",
    "\n",
    "```\n",
    "return left_indices, right_indices\n",
    "```\n",
    "\n",
    "````\n",
    "```\n",
    "<details>\n",
    "      <summary><font size=\"2\" color=\"darkblue\"><b>Daha fazla ipucu için tıklayın</b></font></summary>\n",
    "    \n",
    "Şart şu olacak: <code> if X[i][feature] == 1:</code>.\n",
    "    \n",
    "</details>\n",
    "````\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05657d8f",
   "metadata": {},
   "source": [
    "Şimdi implementasyonunuzu kontrol edelim. Aşağıdaki kod blokları ile root node’daki veriyi feature 0 (Brown Cap) kullanarak bölelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39260b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
      "Right indices:  [5, 6, 8]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Root node indeksi (tüm örnekler)\n",
    "root_indices = list(range(len(X_train)))\n",
    "\n",
    "# Feature 0 (Brown Cap) ile bölme\n",
    "left_indices, right_indices = split_dataset(X_train, root_indices, 0)\n",
    "\n",
    "print(\"Left indices (feature 0 = 1):\", left_indices)\n",
    "print(\"Right indices (feature 0 = 0):\", right_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6780625",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "```\n",
    "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
    "Right indices:  [5, 6, 8]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4b739",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "\n",
    "### 4.3 Bilgi Kazancını Hesaplama\n",
    "\n",
    "Sonraki adımda, `information_gain` adlı bir fonksiyon yazacaksınız. Bu fonksiyon, eğitim verisini, bir node’daki indeksleri ve hangi feature’a göre bölüneceğini alacak ve bölünmeden elde edilen bilgi kazancını döndürecek.\n",
    "\n",
    "<a name=\"ex03\"></a>\n",
    "\n",
    "### Alıştırma 3\n",
    "\n",
    "Aşağıdaki `compute_information_gain()` fonksiyonunu tamamlayarak şu formülü hesaplayın:\n",
    "\n",
    "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
    "\n",
    "Burada:\n",
    "\n",
    "* $H(p_1^\\text{node})$ node’daki entropi\n",
    "* $H(p_1^\\text{left})$ ve $H(p_1^\\text{right})$ bölünmeden sonra oluşan sol ve sağ dallardaki entropiler\n",
    "* $w^{\\text{left}}$ ve $w^{\\text{right}}$ sol ve sağ dalda bulunan örneklerin oranları\n",
    "\n",
    "Notlar:\n",
    "\n",
    "* Entropiyi hesaplamak için yukarıda implement ettiğiniz `compute_entropy()` fonksiyonunu kullanabilirsiniz\n",
    "* Dataseti bölmek için yukarıda yazdığınız `split_dataset()` fonksiyonu starter kodda sağlanmıştır\n",
    "\n",
    "Takıldığınızda, hücre altında verilen ipuçlarına göz atabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaafabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_information_gain\n",
    "\n",
    "def compute_information_gain(X, y, node_indices, feature):\n",
    "    \n",
    "    \"\"\"\n",
    "    Belirli bir feature’a göre node’u bölmenin bilgi kazancını hesaplar.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            (n_samples, n_features) boyutunda veri matrisi\n",
    "        y (array like):         Hedef değişkeni içeren n_samples uzunluğunda liste veya ndarray\n",
    "        node_indices (ndarray): O anki node’da aktif olan örneklerin indeksleri\n",
    "   \n",
    "    Returns:\n",
    "        cost (float):        Hesaplanan bilgi kazancı\n",
    "    \"\"\"    \n",
    "    # Dataseti böl\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "    \n",
    "    # Kullanışlı değişkenler\n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[right_indices], y[right_indices]\n",
    "    \n",
    "    # Hesaplanacak değişken\n",
    "    information_gain = 0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    left_entropy = compute_entropy(y_left)\n",
    "    right_entropy = compute_entropy(y_right)\n",
    "    \n",
    "    # Ağırlıklar\n",
    "    w_left = len(X_left) / len(X_node)\n",
    "    w_right = len(X_right) / len(X_node)\n",
    "    \n",
    "    # Ağırlıklı entropi\n",
    "    weighted_entropy = w_left * left_entropy + w_right * right_entropy\n",
    "    \n",
    "    # Bilgi kazancı\n",
    "    information_gain = node_entropy - weighted_entropy\n",
    "    \n",
    "    ### END CODE HERE ###  \n",
    "    \n",
    "    return information_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06d3e9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    \n",
    "    \n",
    "   * Here's how you can structure the overall implementation for this function\n",
    "    ```python \n",
    "    def compute_information_gain(X, y, node_indices, feature):\n",
    "        # Split dataset\n",
    "        left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "\n",
    "        # Some useful variables\n",
    "        X_node, y_node = X[node_indices], y[node_indices]\n",
    "        X_left, y_left = X[left_indices], y[left_indices]\n",
    "        X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "        # You need to return the following variables correctly\n",
    "        information_gain = 0\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        # Your code here to compute the entropy at the node using compute_entropy()\n",
    "        node_entropy = \n",
    "        # Your code here to compute the entropy at the left branch\n",
    "        left_entropy = \n",
    "        # Your code here to compute the entropy at the right branch\n",
    "        right_entropy = \n",
    "\n",
    "        # Your code here to compute the proportion of examples at the left branch\n",
    "        w_left = \n",
    "        \n",
    "        # Your code here to compute the proportion of examples at the right branch\n",
    "        w_right = \n",
    "\n",
    "        # Your code here to compute weighted entropy from the split using \n",
    "        # w_left, w_right, left_entropy and right_entropy\n",
    "        weighted_entropy = \n",
    "\n",
    "        # Your code here to compute the information gain as the entropy at the node\n",
    "        # minus the weighted entropy\n",
    "        information_gain = \n",
    "        ### END CODE HERE ###  \n",
    "\n",
    "        return information_gain\n",
    "    ```\n",
    "    If you're still stuck, check out the hints below.\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b> Hint to calculate the entropies</b></font></summary>\n",
    "        \n",
    "    <code>node_entropy = compute_entropy(y_node)</code><br>\n",
    "    <code>left_entropy = compute_entropy(y_left)</code><br>\n",
    "    <code>right_entropy = compute_entropy(y_right)</code>\n",
    "        \n",
    "    </details>\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate w_left and w_right</b></font></summary>\n",
    "           <code>w_left = len(X_left) / len(X_node)</code><br>\n",
    "           <code>w_right = len(X_right) / len(X_node)</code>\n",
    "    </details>\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate weighted_entropy</b></font></summary>\n",
    "           <code>weighted_entropy = w_left * left_entropy + w_right * right_entropy</code>\n",
    "    </details>\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to calculate information_gain</b></font></summary>\n",
    "           <code> information_gain = node_entropy - weighted_entropy</code>\n",
    "    </details>\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76606fa",
   "metadata": {},
   "source": [
    "Artık uygulamanızı aşağıdaki hücre ile test edebilir ve her bir feature’a göre bölmenin bilgi kazancını hesaplayabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c51f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain from splitting the root on brown cap:  0.034851554559677034\n",
      "Information Gain from splitting the root on tapering stalk shape:  0.12451124978365313\n",
      "Information Gain from splitting the root on solitary:  0.2780719051126377\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0)\n",
    "print(\"Kök düğümün kahverengi şapka özelliğine göre bölünmesinden elde edilen Bilgi Kazancı: \", info_gain0)\n",
    "    \n",
    "info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1)\n",
    "print(\"Kök düğümün konik sap şekli özelliğine göre bölünmesinden elde edilen Bilgi Kazancı: \", info_gain1)\n",
    "\n",
    "info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2)\n",
    "print(\"Kök düğümün tek başına özelliğine göre bölünmesinden elde edilen Bilgi Kazancı: \", info_gain2)\n",
    "\n",
    "# BİRİM TESTLERİ\n",
    "compute_information_gain_test(compute_information_gain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd83a5",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "```\n",
    "Information Gain from splitting the root on brown cap:  0.034851554559677034\n",
    "Information Gain from splitting the root on tapering stalk shape:  0.12451124978365313\n",
    "Information Gain from splitting the root on solitary:  0.2780719051126377\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1f628",
   "metadata": {},
   "source": [
    "Splitting on \"Solitary\" (feature = 2) at the root node gives the maximum information gain. Therefore, it's the best feature to split on at the root node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf267c",
   "metadata": {},
   "source": [
    "<a name=\"4.4\"></a>\n",
    "\n",
    "### 4.4  En iyi bölünmeyi bul\n",
    "\n",
    "Şimdi, her özellik için bilgi kazancını hesaplayarak en iyi bölünmeyi sağlayan özelliği döndüren bir fonksiyon yazalım.\n",
    "\n",
    "<a name=\"ex04\"></a>\n",
    "\n",
    "### Alıştırma 4\n",
    "\n",
    "Aşağıdaki `get_best_split()` fonksiyonunu tamamlayın.\n",
    "\n",
    "* Fonksiyon, eğitim verilerini ve o düğümdeki veri noktalarının indekslerini alır\n",
    "* Fonksiyonun çıktısı, maksimum bilgi kazancını sağlayan özelliktir\n",
    "\n",
    "  * Her özellik için bilgi kazancını hesaplamak için `compute_information_gain()` fonksiyonunu kullanabilirsiniz.\n",
    "  * Takılırsanız, aşağıdaki ipuçlarına göz atabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1506615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# DEĞERLENDİRİLEN FONKSİYON: get_best_split\n",
    "\n",
    "def get_best_split(X, y, node_indices):   \n",
    "    \"\"\"\n",
    "    Düğüm verilerini bölmek için optimal özellik ve eşik değerini döndürür\n",
    "    \n",
    "    Argümanlar:\n",
    "        X (ndarray):            Şekli (n_samples, n_features) olan veri matrisi\n",
    "        y (array like):         Hedef değişkeni içeren n_samples uzunluğunda liste veya ndarray\n",
    "        node_indices (ndarray): Aktif indeksleri içeren liste. Yani, bu adımda değerlendirilen örnekler.\n",
    "\n",
    "    Döndürür:\n",
    "        best_feature (int):     Bölme için en iyi özelliğin indeksi\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Bazı faydalı değişkenler\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    # Aşağıdaki değişkenleri doğru şekilde döndürmeniz gerekiyor\n",
    "    best_feature = -1\n",
    "    \n",
    "    ### KODU BURADAN BAŞLAT ###\n",
    "    max_info_gain=0\n",
    "    for feature in range(num_features):\n",
    "        info_gain = compute_information_gain(X, y, node_indices, feature)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "                \n",
    "        \n",
    "    ### KODU BURADA BİTİR ##    \n",
    "       \n",
    "    return best_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af14d9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><font size=\"3\" color=\"darkgreen\"><b>Click for hints</b></font></summary>\n",
    "    \n",
    "    \n",
    "   * Here's how you can structure the overall implementation for this function\n",
    "    \n",
    "    ```python \n",
    "    def get_best_split(X, y, node_indices):   \n",
    "\n",
    "        # Some useful variables\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        # You need to return the following variables correctly\n",
    "        best_feature = -1\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "        max_info_gain = 0\n",
    "\n",
    "        # Iterate through all features\n",
    "        for feature in range(num_features): \n",
    "            \n",
    "            # Your code here to compute the information gain from splitting on this feature\n",
    "            info_gain = \n",
    "            \n",
    "            # If the information gain is larger than the max seen so far\n",
    "            if info_gain > max_info_gain:  \n",
    "                # Your code here to set the max_info_gain and best_feature\n",
    "                max_info_gain = \n",
    "                best_feature = \n",
    "        ### END CODE HERE ##    \n",
    "   \n",
    "    return best_feature\n",
    "    ```\n",
    "    If you're still stuck, check out the hints below.\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b> Hint to calculate info_gain</b></font></summary>\n",
    "        \n",
    "    <code>info_gain = compute_information_gain(X, y, node_indices, feature)</code>\n",
    "    </details>\n",
    "    \n",
    "    <details>\n",
    "          <summary><font size=\"2\" color=\"darkblue\"><b>Hint to update the max_info_gain and best_feature</b></font></summary>\n",
    "           <code>max_info_gain = info_gain</code><br>\n",
    "           <code>best_feature = feature</code>\n",
    "    </details>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96080f75",
   "metadata": {},
   "source": [
    "Now, let's check the implementation of your function using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2cfe8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature to split on: 2\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "best_feature = get_best_split(X_train, y_train, root_indices)\n",
    "print(\"Best feature to split on: %d\" % best_feature)\n",
    "\n",
    "# UNIT TESTS\n",
    "get_best_split_test(get_best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb06c10",
   "metadata": {},
   "source": [
    "Yukarıda gördüğümüz gibi, fonksiyon kök düğümde bölme için en iyi özellik olarak özellik 2’yi (“Solitary”) döndürüyor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299663c9",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "\n",
    "## 5 - Ağacı Oluşturma\n",
    "\n",
    "Bu bölümde, yukarıda uyguladığınız fonksiyonları kullanarak bir karar ağacı oluşturacağız. Bunu, durma kriterine ulaşana kadar (maksimum derinlik 2) her seferinde bölmek için en iyi özelliği seçerek yapacağız.\n",
    "\n",
    "Bu bölüm için herhangi bir şey implement etmenize gerek yok.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83485150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not graded\n",
    "tree = []\n",
    "\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
    "    \"\"\"\n",
    "    Her düğümde veri setini 2 alt gruba bölen özyinelemeli algoritmayı kullanarak bir ağaç oluşturur.\n",
    "    Bu fonksiyon sadece ağacı yazdırır.\n",
    "    \n",
    "    Argümanlar:\n",
    "        X (ndarray):            Şekli (n_samples, n_features) olan veri matrisi\n",
    "        y (array like):         Hedef değişkeni içeren n_samples uzunluğunda liste veya ndarray\n",
    "        node_indices (ndarray): Aktif indeksleri içeren liste. Yani, bu adımda değerlendirilen örnekler.\n",
    "        branch_name (string):   Dalın adı. ['Root', 'Left', 'Right']\n",
    "        max_depth (int):        Oluşacak ağacın maksimum derinliği\n",
    "        current_depth (int):    Mevcut derinlik. Özyinelemeli çağrı sırasında kullanılan parametre.\n",
    "   \n",
    "    \"\"\" \n",
    "\n",
    "    # Maksimum derinliğe ulaşıldı - bölmeyi durdur\n",
    "    if current_depth == max_depth:\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        print(formatting, \"%s yaprak düğüm, indeksler:\" % branch_name, node_indices)\n",
    "        return\n",
    "   \n",
    "    # Aksi takdirde, en iyi bölmeyi al ve veriyi böl\n",
    "    # Bu düğümdeki en iyi özellik ve eşik değerini al\n",
    "    best_feature = get_best_split(X, y, node_indices) \n",
    "    tree.append((current_depth, branch_name, best_feature, node_indices))\n",
    "    \n",
    "    formatting = \"-\"*current_depth\n",
    "    print(\"%s Derinlik %d, %s: Özellik %d üzerinde böl\" % (formatting, current_depth, branch_name, best_feature))\n",
    "    \n",
    "    # Veri setini en iyi özellik üzerinde böl\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "    \n",
    "    # Sol ve sağ alt düğümleri bölmeye devam et. Mevcut derinliği artır\n",
    "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1)\n",
    "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfe3770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0, Root: Split on feature: 2\n",
      "- Depth 1, Left: Split on feature: 0\n",
      "  -- Left leaf node with indices [0, 1, 4, 7]\n",
      "  -- Right leaf node with indices [5]\n",
      "- Depth 1, Right: Split on feature: 1\n",
      "  -- Left leaf node with indices [8]\n",
      "  -- Right leaf node with indices [2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4975fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
